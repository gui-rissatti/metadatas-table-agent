{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3461d8bf",
   "metadata": {},
   "source": [
    "# Agente de Metadados do Databricks\n",
    "\n",
    "Este notebook carrega um script que gera descrições de tabelas e colunas a partir de um arquivo CSV de metadados, usando um LLM do Google (Gemini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792c861",
   "metadata": {},
   "source": [
    "## Importações e configuração do ambiente\n",
    "\n",
    "Nesta seção importamos as bibliotecas necessárias, carregamos variáveis de ambiente e definimos configurações gerais do agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb5c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import traceback\n",
    "\n",
    "# Carregar variáveis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- configuração ---\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    pass\n",
    "\n",
    "LLM_MODEL = \"gemini-2.5-flash\" \n",
    "BATCH_SIZE = 10 # Processar 10 tabelas por chamada ao LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fbef54",
   "metadata": {},
   "source": [
    "## Estado do agente (Graph State)\n",
    "\n",
    "Aqui definimos a estrutura de estado compartilhado entre os nós do grafo, incluindo informações sobre o arquivo de metadados, tabelas pendentes e resultados gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b205047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Estado do grafo ---\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    metadata_file_path: str\n",
    "    pending_tables: List[str]\n",
    "    current_batch: List[str]\n",
    "    current_batch_schemas: Dict[str, Dict[str, Any]]\n",
    "    generated_batch_descriptions: str # String JSON de lista de TableDocumentation\n",
    "    completed_updates: List[Dict[str, str]] # Acompanhar atualizações concluídas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44eb2c",
   "metadata": {},
   "source": [
    "## Ferramenta para leitura do CSV de metadados\n",
    "\n",
    "Nesta parte definimos a ferramenta que lê o arquivo CSV, identifica tabelas com descrições faltantes (de tabela ou de coluna) e retorna a lista de tabelas que precisam de documentação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14b421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Definição de ferramentas ---\n",
    "\n",
    "@tool\n",
    "def parse_metadata_csv(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Lê o CSV de metadados. Filtra tabelas em que a coluna 'description' está vazia OU alguma\n",
    "    'column_description' está vazia.\n",
    "    Retorna uma lista de nomes de tabelas totalmente qualificados (catalog_path) que precisam de documentação.\n",
    "    \"\"\"\n",
    "    print(f\"--- [Tool] Parsing CSV: {file_path} ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['description'] = df['description'].fillna('')\n",
    "        df['column_description'] = df['column_description'].fillna('')\n",
    "        missing_table_desc = df[df['description'].str.strip() == '']['catalog_path'].unique()\n",
    "        missing_col_desc = df[df['column_description'].str.strip() == '']['catalog_path'].unique()\n",
    "        pending = list(set(missing_table_desc) | set(missing_col_desc))\n",
    "\n",
    "        print(f\"--- [Tool] Found {len(pending)} tables needing documentation (table or column level) ---\")\n",
    "\n",
    "        return pending\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f606488",
   "metadata": {},
   "source": [
    "## Nós principais do grafo (loader, dispatcher, geração)\n",
    "\n",
    "Agora definimos os nós que compõem o fluxo do agente: carregamento inicial das tabelas, preparação dos lotes de esquemas e chamada ao LLM para geração das descrições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42f106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Nós do grafo ---\n",
    "\n",
    "def loader_node(state: AgentState):\n",
    "\n",
    "    print(\"--- [Node] Loader ---\")\n",
    "\n",
    "    file_path = state.get(\"metadata_file_path\")\n",
    "    pending_tables = parse_metadata_csv.invoke(file_path)\n",
    "\n",
    "    print(f\"--- [Node] Loader - Found {len(pending_tables)} tables to process ---\")\n",
    "\n",
    "    return {\"pending_tables\": pending_tables, \"completed_updates\": []}\n",
    "\n",
    "def dispatcher_node(state: AgentState):\n",
    "\n",
    "    print(\"--- [Node] Dispatcher ---\")\n",
    "\n",
    "    pending = state.get(\"pending_tables\", [])\n",
    "    if not pending:\n",
    "        return {\"current_batch\": []}\n",
    "\n",
    "    # Selecionar um lote de tabelas\n",
    "\n",
    "    batch_tables = pending[:BATCH_SIZE]\n",
    "    remaining = pending[BATCH_SIZE:]\n",
    "\n",
    "    file_path = state.get(\"metadata_file_path\")\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    batch_schemas = {}\n",
    "\n",
    "    for table in batch_tables:\n",
    "        schema_df = df[df['catalog_path'] == table]\n",
    "        schema = {}\n",
    "        for _, row in schema_df.iterrows():\n",
    "            col_name = row['column_name']\n",
    "            col_type = row['column_type']\n",
    "            col_desc = row.get('column_description', '')\n",
    "            if pd.isna(col_desc): col_desc = \"\"\n",
    "            schema[col_name] = {\n",
    "                \"type\": col_type,\n",
    "                \"description\": str(col_desc)\n",
    "            }\n",
    "        batch_schemas[table] = schema\n",
    "\n",
    "    print(f\"--- [Node] Dispatcher - Prepared batch of {len(batch_tables)} tables ---\")\n",
    "\n",
    "    return {\n",
    "        \"current_batch\": batch_tables,\n",
    "        \"pending_tables\": remaining,\n",
    "        \"current_batch_schemas\": batch_schemas\n",
    "    }\n",
    "\n",
    "class TableDocs(BaseModel):\n",
    "    table_name: str\n",
    "    table_description: str = Field(description=\"A descrição da tabela.\")\n",
    "    column_descriptions: Dict[str, str] = Field(description=\"Dicionário que mapeia nomes de colunas para descrições.\")\n",
    "\n",
    "class BatchTableDocs(BaseModel):\n",
    "    tables: List[TableDocs]\n",
    "\n",
    "def generation_node(state: AgentState):\n",
    "\n",
    "    print(\"--- [Node] Generation (Batch) ---\")\n",
    "    batch_tables = state[\"current_batch\"]\n",
    "    batch_schemas = state[\"current_batch_schemas\"]\n",
    "\n",
    "    if not batch_tables:\n",
    "        return {\"generated_batch_descriptions\": json.dumps([])}\n",
    "\n",
    "    # Lógica simples de limitação de taxa (rate limiting)\n",
    "    time.sleep(4) # Limite de 15 RPM = 1 requisição a cada 4s. Com batching, isso é suficiente.\n",
    "\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "\n",
    "        print(\"WARNING: GOOGLE_API_KEY not found in environment variables.\")\n",
    "        return {\"generated_batch_descriptions\": json.dumps([])}\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0, google_api_key=api_key, max_retries=10)\n",
    "    structured_llm = llm.with_structured_output(BatchTableDocs)\n",
    "\n",
    "    # Preparar prompt com todos os esquemas\n",
    "    schemas_str = json.dumps(batch_schemas, indent=2)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a Databricks data steward. You must generate documentation for multiple tables and their columns in Brazilian Portuguese.\"),\n",
    "        (\"user\", \"\"\"\n",
    "        You will receive a JSON dictionary where keys are table names and values are their schemas (columns and existing descriptions).\n",
    "         \n",
    "        Input Schemas:\n",
    "        {schemas}\n",
    "         \n",
    "        Task:\n",
    "         \n",
    "        For EACH table in the input:         \n",
    "        1. Generate a professional, concise description for the TABLE in Brazilian Portuguese.\n",
    "        2. Generate a concise description for EACH COLUMN in Brazilian Portuguese.\n",
    "           - If a column already has a good description, you can keep it or refine it.\n",
    "           - If it is missing (empty), you MUST generate one based on the column name and type.\n",
    "           - Ensure output maps correctly to the provided table names.\n",
    "        Return ONLY the JSON structure matching the BatchTableDocs schema (a list of table documentations).\n",
    "        \"\"\")\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        chain = prompt | structured_llm\n",
    "        result = chain.invoke({\"schemas\": schemas_str})\n",
    "        # desc_data = result.dict()  # Para compatibilidade com Pydantic v1\n",
    "        desc_data = result.model_dump()  # Para compatibilidade com Pydantic v2\n",
    "        desc_str = json.dumps(desc_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"LLM Batch Generation Error: {e}\")\n",
    "        desc_str = json.dumps({\"tables\": []})\n",
    "    return {\"generated_batch_descriptions\": desc_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a5998",
   "metadata": {},
   "source": [
    "## Nós de commit e salvamento\n",
    "\n",
    "Aqui acumulamos as descrições geradas em memória e, ao final do processamento, gravamos as atualizações em arquivos CSV e Excel de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837565c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_node(state: AgentState):\n",
    "\n",
    "    print(\"--- [Node] Commit (Accumulate Batch) ---\")\n",
    "    desc_json = state[\"generated_batch_descriptions\"]\n",
    "    try:\n",
    "        data = json.loads(desc_json)\n",
    "        tables_data = data.get(\"tables\", [])\n",
    "        print(f\"Committing {len(tables_data)} results from batch...\")\n",
    "        new_updates = []\n",
    "        for item in tables_data:\n",
    "            # item é um dicionário correspondente ao modelo TableDocs\n",
    "            # Re-serializar para manter a estrutura usada antes ou adaptar save_node\n",
    "            # Vamos armazenar atualizações individuais como antes para minimizar mudanças em save_node\n",
    "            # Precisamos do nome da tabela, descrição da tabela e descrições de colunas\n",
    "            # A estrutura usada antes em 'documentation' era {table_desc, column_descriptions}\n",
    "            # aqui temos {table_name, table_description, column_descriptions}\n",
    "\n",
    "            doc_obj = {\n",
    "                \"table_description\": item[\"table_description\"],\n",
    "                \"column_descriptions\": item[\"column_descriptions\"]\n",
    "            }\n",
    "\n",
    "            new_updates.append({\n",
    "                \"catalog_path\": item[\"table_name\"],\n",
    "                \"documentation\": json.dumps(doc_obj)\n",
    "            })\n",
    "\n",
    "        existing_updates = state.get(\"completed_updates\", [])\n",
    "\n",
    "        return {\"completed_updates\": existing_updates + new_updates}\n",
    "\n",
    "    except Exception as e:        \n",
    "        print(f\"Error parsing batch results: {e}\")\n",
    "        return {}\n",
    "\n",
    "def save_node(state: AgentState):\n",
    "\n",
    "    print(\"--- [Node] Save (Output CSV & XLSX) ---\")\n",
    "\n",
    "    updates = state.get(\"completed_updates\", [])\n",
    "    file_path = state.get(\"metadata_file_path\")\n",
    "    \n",
    "    base_dir = os.getcwd()\n",
    "    output_dir = os.path.join(base_dir, \"output\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_csv = os.path.join(output_dir, \"updated_metadata.csv\")\n",
    "    output_xlsx = os.path.join(output_dir, \"updated_metadata.xlsx\")\n",
    "\n",
    "    print(f\"Saving {len(updates)} table updates to {output_csv} and {output_xlsx}...\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        table_desc_map = {}\n",
    "        col_desc_map = {}\n",
    "\n",
    "        for item in updates:\n",
    "            t_name = item[\"catalog_path\"]\n",
    "\n",
    "            try:\n",
    "                doc = json.loads(item[\"documentation\"])\n",
    "                t_desc = doc.get(\"table_description\", \"\")\n",
    "                c_descs = doc.get(\"column_descriptions\", {})\n",
    "                table_desc_map[t_name] = t_desc\n",
    "\n",
    "                for col, desc in c_descs.items():\n",
    "                    col_desc_map[(t_name, col)] = desc\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        def update_table_desc(row):\n",
    "            if row['catalog_path'] in table_desc_map:\n",
    "                new_desc = table_desc_map[row['catalog_path']]\n",
    "\n",
    "                if new_desc: return new_desc\n",
    "            return row['description']\n",
    "\n",
    "        df['description'] = df.apply(update_table_desc, axis=1)\n",
    "\n",
    "        def update_col_desc(row):\n",
    "            key = (row['catalog_path'], row['column_name'])\n",
    "\n",
    "            if key in col_desc_map:\n",
    "                return col_desc_map[key]\n",
    "\n",
    "            return row['column_description']\n",
    "\n",
    "        df['column_description'] = df.apply(update_col_desc, axis=1)\n",
    "        df.to_csv(output_csv, index=False, sep=';')\n",
    "\n",
    "        print(\"CSV saved.\")\n",
    "\n",
    "        df.to_excel(output_xlsx, index=False)\n",
    "        print(\"Excel saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"Error saving files: {e}\")\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da84667",
   "metadata": {},
   "source": [
    "## Lógica de transição entre nós e definição do grafo\n",
    "\n",
    "Nesta parte definimos para onde o fluxo segue após cada nó, montamos o grafo de estados e preparamos o aplicativo (app) para execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99988d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Lógica de arestas (transições) ---\n",
    "\n",
    "def should_process_next(state: AgentState):\n",
    "    if state.get(\"current_batch\"):\n",
    "        return \"generation_node\"\n",
    "    return \"save_node\"\n",
    "\n",
    "# --- 5. Definição do grafo ---\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"loader_node\", loader_node)\n",
    "workflow.add_node(\"dispatcher_node\", dispatcher_node)\n",
    "workflow.add_node(\"generation_node\", generation_node)\n",
    "workflow.add_node(\"commit_node\", commit_node)\n",
    "workflow.add_node(\"save_node\", save_node)\n",
    "workflow.set_entry_point(\"loader_node\")\n",
    "workflow.add_edge(\"loader_node\", \"dispatcher_node\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"dispatcher_node\",\n",
    "    should_process_next,\n",
    "    {\n",
    "        \"generation_node\": \"generation_node\",\n",
    "        \"save_node\": \"save_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generation_node\", \"commit_node\")\n",
    "workflow.add_edge(\"commit_node\", \"dispatcher_node\")\n",
    "workflow.add_edge(\"save_node\", END)\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093a47d",
   "metadata": {},
   "source": [
    "## Execução do agente\n",
    "\n",
    "Por fim, definimos o ponto de entrada (quando o arquivo é executado como script) e iniciamos o processamento dos metadados, usando o CSV de entrada configurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7aa9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Databricks Metadata Agent (Batch Size: 10)...\n",
      "--- [Node] Loader ---\n",
      "--- [Tool] Parsing CSV: c:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\data\\New_Query_2025_12_14_11_05pm (3).csv ---\n",
      "--- [Tool] Found 1200 tables needing documentation (table or column level) ---\n",
      "--- [Node] Loader - Found 1200 tables to process ---\n",
      "--- [Node] Dispatcher ---\n",
      "--- [Node] Dispatcher - Prepared batch of 10 tables ---\n",
      "--- [Node] Generation (Batch) ---\n",
      "LLM Batch Generation Error: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 24.462495094s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "--- [Node] Commit (Accumulate Batch) ---\n",
      "Committing 0 results from batch...\n",
      "--- [Node] Dispatcher ---\n",
      "--- [Node] Dispatcher - Prepared batch of 10 tables ---\n",
      "--- [Node] Generation (Batch) ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m initial_state = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata_file_path\u001b[39m\u001b[33m\"\u001b[39m: csv_path,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpending_tables\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompleted_updates\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m     13\u001b[39m }\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Aumentar o limite de recursão para lidar com muitos lotes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m \n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent workflow completed.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mgeneration_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    107\u001b[39m     chain = prompt | structured_llm\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     result = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mschemas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mschemas_str\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# desc_data = result.dict()  # Para compatibilidade com Pydantic v1\u001b[39;00m\n\u001b[32m    110\u001b[39m     desc_data = result.model_dump()  \u001b[38;5;66;03m# Para compatibilidade com Pydantic v2\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2529\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2526\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3040\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3027\u001b[39m request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   3028\u001b[39m     messages,\n\u001b[32m   3029\u001b[39m     stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3037\u001b[39m     **kwargs,\n\u001b[32m   3038\u001b[39m )\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3044\u001b[39m     _handle_client_error(e, request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5201\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5202\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5204\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5205\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5207\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5208\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\google\\genai\\models.py:3985\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3982\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   3983\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   3990\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3991\u001b[39m ):\n\u001b[32m   3992\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1380\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1383\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1384\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1385\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m   response_body = (\n\u001b[32m   1390\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m   )\n\u001b[32m   1392\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1220\u001b[39m     retry_kwargs = retry_args(parameter_model.retry_options)\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:487\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    486\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\.venv\\Lib\\site-packages\\tenacity\\nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_path = r\"c:\\Users\\guilh\\OneDrive\\Documentos\\PROFISSIONAL\\PROJETOS\\agents\\tables_metadata\\data\\New_Query_2025_12_14_11_05pm (3).csv\"\n",
    "\n",
    "    print(f\"Starting Databricks Metadata Agent (Batch Size: {BATCH_SIZE})...\")\n",
    "\n",
    "    initial_state = {\n",
    "        \"metadata_file_path\": csv_path,\n",
    "        \"pending_tables\": [],\n",
    "        \"current_batch\": [],\n",
    "        \"current_batch_schemas\": {},\n",
    "        \"generated_batch_descriptions\": \"\",\n",
    "        \"completed_updates\": []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Aumentar o limite de recursão para lidar com muitos lotes\n",
    "        for output in app.stream(initial_state, config={\"recursion_limit\": 1000000}):\n",
    "            pass \n",
    "        print(\"Agent workflow completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
